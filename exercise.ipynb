{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Boot Camp\n",
    "\n",
    "***\n",
    "\n",
    "## Table of contents:\n",
    "\n",
    "* [Images as arrays](#first)   \n",
    "* [Image color space](#second)\n",
    "* [Image data types](#third)\n",
    "* [Plotting images](#fourth)\n",
    "* [Images in Deep Learning frameworks](#fifth)\n",
    "* [Simple image manipulation](#sixth)\n",
    "* [Loading a set of images](#seventh)\n",
    "* [Segmentation maps](#eighth)\n",
    "* [Batching](#ninth)\n",
    "* [Convolutions](#tenth)\n",
    "* [Data augmentation](#eleventh)\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "Welcome!\n",
    "In this notebook, we will go through some basic image processing in Python and familiarize ourselves with different utilities that can be useful for any Deep Learning pipeline, utilities provides through libraries like `skimage`, `imgaug`, `glob`, `tqdm` and more.\n",
    "\n",
    "We will be using sample images from this **[three-dimensional X-ray microtomography thalamocortical dataset](https://github.com/nerdslab/xray-thc)**, used to characterize brain heterogeneity. These samples, imaged in the Striatum and Hypothalamus regions of a mouse brain, were annotated to get microstructure segmentation maps (of cell bodies, blood vessels, and myelinated axons). The full dataset is available on [bossdb](https://bossdb.org/project/prasad2020)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>Set your python kernel to <code>00-boot</code></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as arrays <a class=\"anchor\" id=\"first\"></a>\n",
    "\n",
    "Images are represented as numpy arrays of shape (height, width, channels).\n",
    "\n",
    "![RGB image as a numpy array](./assets/image_as_array.png)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrerâ€™s Blog</a></div>\n",
    "\n",
    "\n",
    "Multiple utilities/packages exist to read images from files in Python,\n",
    "we will use `skimage.io.imread`.\n",
    "\n",
    "\n",
    "If you look in the directory containing this notebook, you will find a folder called data which includes some tiff files. \n",
    "Here our images have the .tiff extension and all start with \"img\".\n",
    "\n",
    "Let's load one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "img = io.imread('data/img_650_1162__600_1112__0.tiff')\n",
    "print('Type:', type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image color space <a class=\"anchor\" id=\"second\"></a>\n",
    "If the image is in grayscale, then the number of channels is equal to 1,\n",
    "in which case the array can also be of shape (height, width).\n",
    "If the image is RGB, then the number of channels is 3\n",
    "with each channel encoding the red, green and blue components.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>Is <code>img</code> RGB or grayscale ?</b></div>\n",
    "\n",
    "<div style=\"text-align: right\"> Help: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">Numpy cheatsheet</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Reshape <code>img</code> such that its shape is <code>(height, width, 1)</code> </b></div>\n",
    "\n",
    "<div style=\"text-align: right\"> Hint: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\">expand dims</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data types <a class=\"anchor\" id=\"third\"></a>\n",
    "\n",
    "\n",
    "Images can be represented by a variety of data types. The following is a list of the most common datatypes:\n",
    "- `bool`: binary, 0 or 1\n",
    "- `uint8`: unsigned integers, 0 to 255 range\n",
    "- `float`: -1 to 1 or 0 to 1\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> What is the data type of <code> img</code>? What are the minimum and maximum intensity values? </b>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: right\"> Help: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">Numpy cheatsheet</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images <a class=\"anchor\" id=\"fourth\"></a>\n",
    "\n",
    "Using `matplotlib`, we can visualize the image. <br> When the image is in grayscale,\n",
    "a colormap can be specified using the `cmap` argument. <br> By default,\n",
    "the colormap is `viridis`, in the following cell we will use `gray`.\n",
    "\n",
    "> Useful `matplotlib` resources:\n",
    "> - [matplotlib cheatsheets](https://github.com/matplotlib/cheatsheets)\n",
    "> - [colormaps in matplotlib](https://matplotlib.org/stable/tutorials/colors/colormaps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Images in Deep Learning frameworks <a class=\"anchor\" id=\"fifth\"></a>\n",
    "\n",
    "\n",
    "In pytorch, tensorflow or jax (ML libraries that we will soon be using), images are represented as (channels, height, width)\n",
    "and are rescaled to be in the [0, 1] range.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>Generate a new image that respects these conventions.</b> You can use <code>np.transpose</code></div>\n",
    "\n",
    "<div style=\"text-align: right\"> Help: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\">Numpy Transpose</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple image manipulation <a class=\"anchor\" id=\"sixth\"></a>\n",
    "\n",
    "Given that images are numpy arrays, we can take advantage of the powerful\n",
    " [indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html)\n",
    " to perform simple transformations like cropping, downsampling and flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cropping\n",
    "cropped_img = img[10:310, 50:350]\n",
    "\n",
    "# downsampling\n",
    "factor = 2\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "\n",
    "# horizontal flip\n",
    "hflip_img = img[:,::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5), frameon=False)\n",
    "\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[0].set_title('Original image\\nSize = {}'.format(str(img.shape)))\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(cropped_img, cmap='gray')\n",
    "axs[1].set_title('Cropped image\\nSize = {}'.format(str(cropped_img.shape)))\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(downsampled_img, cmap='gray')\n",
    "axs[2].set_title('Downsampled image\\nSize = {}'.format(str(downsampled_img.shape)))\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(hflip_img, cmap='gray')\n",
    "axs[3].set_title('Horizontal Flip\\n Size = {}'.format(str(hflip_img.shape)))\n",
    "axs[3].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b> Apply the following transformations:</b> <br>\n",
    "<li>Center crop of size <code>(256, 256)</code></li>\n",
    "<li>Vertical Flip</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><h1>Checkpoint 1</h1>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a set of images <a class=\"anchor\" id=\"seventh\"></a>\n",
    "\n",
    "Given a set of images in a folder, we need to be able to easily find the pathnames and load them in. <br>\n",
    "`glob` is a standard package that provides a utility for finding all pathnames that match a given pattern.\n",
    "\n",
    "Here our images have the `.tiff` extension and all names start with `img`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "root = 'data/'\n",
    "img_filenames = glob(os.path.join(root, 'img*.tiff'))\n",
    "\n",
    "print('Found:')\n",
    "for img_filename in img_filenames:\n",
    "    print(' ', img_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the images. <br>\n",
    "We will use `tqdm` to track progress (even though we only have a small number of images here). <br> `tqdm` provides a progress bar that simply wraps around any iterable, making it useful for tracking training progress, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "imgs = []\n",
    "for fname in tqdm(img_filenames):\n",
    "    img = io.imread(fname)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    imgs.append(img)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i in range(4):\n",
    "    axs[i].imshow(imgs[i], cmap='gray')\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation maps <a class=\"anchor\" id=\"eighth\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We often want to \"segment\" data - i.e: assign labels to parts of images. <br>\n",
    "This dataset has already been segmented for us into four categories: cell bodies, blood vessels, axons, as well as background. <br>\n",
    "For each image file, you will find the corresponding segmentation file in the data folder. These begin with \"annos\" and have the .tiff extension. <br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Using what we have seen thus far, load the segmentation maps into a list called <code>seg_maps</code> and visualize them. <br>Be careful with the file ordering.\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\"> <a href=\"https://pythonbasics.org/replace/\">Hint</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_filenames = ...\n",
    "\n",
    "seg_maps = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that there are 4 unique values in the segmentation maps, each corresponding to one of these four classes:\n",
    "- 0: background\n",
    "- 1: cell\n",
    "- 2: blood vessel\n",
    "- 3: axon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>What is the data type of these segmentation maps?</b>\n",
    "<b>What data types do you know of? How should one choose what data type to use? <br> Should segmentation maps necessarily be saved in the same data type as their respective images? If yes, why? If no, why not?</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Segmentation Maps\n",
    "\n",
    "Let's visualize the segmentation map of one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map_example = seg_maps[0]\n",
    "\n",
    "labels = ['background', 'cells', 'blood vessels', 'axons']\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i in range(4):\n",
    "    tmp = np.zeros_like(seg_map_example)\n",
    "    tmp[seg_map==i] = 1\n",
    "    axs[i].imshow(tmp, cmap='gray')\n",
    "    axs[i].set_title(labels[i])\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching <a class=\"anchor\" id=\"ninth\"></a>\n",
    "\n",
    "In ML/DL, we often have to deal with very large datasets. It soon becomes inefficient to process all the data at once, so it's useful to split the data into \"batches\" that we can process individually. So for purely reasons of computational cost, this is often useful.\n",
    "\n",
    "We will also see another reason for which batching can be useful - for instance when running gradient descent on non-convex landscapes. Here computing the gradient on a subset of the data gives us an approximate/noisy gradient making it less likely for us to end up being stuck in local minima. This is what we call \"stochastic gradient descent\".\n",
    "\n",
    "Let us make our first batch of images, containing $B$ number of images. \n",
    "The shape of the batch will thus get an additional \"batch dimension\" at the first dimension, i.e. (batch_size, channels, height, width).\n",
    "\n",
    "**Q: Make a batch out of the four images (this will be a 4D numpy array)**\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\"> <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.stack.html\">Hint</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><h1>Checkpoint 2</h1>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions <a class=\"anchor\" id=\"tenth\"></a>\n",
    "\n",
    "Convolutions are the elementary operations used in CNNs. The image (and later, the feature maps) are convolved with multiple kernels whose weights are learned. Below is a visual of the pixel values in the output matrix (green) being computed from neighboring pixels in the input matrix (blue). \n",
    "\n",
    "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://github.com/vdumoulin/conv_arithmetic\">Vincent Dumoulin, Francesco Visin</a></div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>\n",
    "    Implement a function that performs \"convolution\". Assume that your image is square and that your kernel is square and has an odd width. <br>Note that your output image will be smaller (we won't use padding for now). </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, kernel):\n",
    "    m = img.shape[0]  #size of original image\n",
    "    k = kernel.shape[0]  #size of filter\n",
    "    \n",
    "    mc = ... #size of the new image after convolution\n",
    "    # NB: there's no one right answer\n",
    "    \n",
    "    conv_img = np.zeros((mc,mc))\n",
    "    \n",
    "    # perform convolution\n",
    "    for ii in range(mc):\n",
    "        for jj in range(mc):\n",
    "            conv_img[ii,jj] = ...\n",
    "            # see Florian's slide for hint\n",
    "            \n",
    "    \n",
    "    return conv_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing filter\n",
    "Convolving the image with a smoothing filter is equivalent to replacing the value of each pixel with the average pixel value within a window of size $d \\times d$ around it.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b> Design a smoothing filter. Try different values of <code>d</code>.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ... # try a kernel size of 10, then try some different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0][:,:,0] # choose one example image\n",
    "smoothed_img = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the original and smoothed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols = 2)\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[0].set_title('original')\n",
    "axs[1].imshow(smoothed_img, cmap='gray')\n",
    "axs[1].set_title('smoothed image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel filter\n",
    "The following is known as the Sobel filter:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 1 \\\\\n",
    "    0 & 0 & 0 \\\\\n",
    "    -1 & -2 & -1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>What pattern would produce the largest output when convolved with this filter? (assuming the sum of the pattern is capped)</b>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Apply the Sobel filter and describe what it does</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><h1>Checkpoint 3</h1>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data augmentation <a class=\"anchor\" id=\"eleventh\"></a>\n",
    "\n",
    "Having collected your hard earned data you want to make the most of it. In ML/DL, we're often limited by the size of our the training set. How could we artificially inflate our data to provide more input to our model and help it generalize better?\n",
    "\n",
    "One trick is to make simple transformations to our data such as rotating it or adding noise - this process is generally called \"data augmentation\" (DA) and is widely used in ML.  \n",
    "\n",
    "`imgaug` is a Python library that provides a very extensive set of image augmentations,\n",
    "and that seamlessly handles complex annotations like segmentation maps, bounding boxes or keypoints. Let us import `imgaug` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# fix the random seed\n",
    "ia.seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Augmenting an image\n",
    "To use an augmentation, we can instantiate an `Augmenter` with a set of hyperparameters.\n",
    "With affine transforamtions for example, we can specify the range of the rotation angle to be `(-45, 45)` degrees.\n",
    "\n",
    "In `imgaug`, the channel-axis is always expected to be the last axis and may be skipped for grayscale images. It is\n",
    "also recommended to work with the `uint8` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rotate = iaa.Affine(rotate=(-45, 45))\n",
    "img_aug = rotate(image=imgs[0])\n",
    "\n",
    "plt.imshow(img_aug, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Try running the previous cell again.\n",
    "\n",
    "#### Augmenting image AND segmentation map\n",
    "\n",
    "When applying certain augmentations, we want to make sure that the segmentation map is changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# convert array to SegmentationMapsOnImage instance\n",
    "seg_map = SegmentationMapsOnImage(seg_maps[0], shape=imgs[0].shape)\n",
    "# augment\n",
    "img_aug, seg_map_aug = rotate(image=imgs[0], segmentation_maps=seg_map)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,5))\n",
    "axs[0].imshow(img_aug, cmap='gray')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(seg_map_aug.draw()[0], cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying multiple augmentations\n",
    "We can compose multiple augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 30)),\n",
    "    iaa.pillike.FilterEdgeEnhanceMore(),\n",
    "    iaa.Crop(percent=(0., 0.2))\n",
    "])\n",
    "\n",
    "imgs_aug = seq(images=imgs)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20,10))\n",
    "axs[0].imshow(np.concatenate((imgs), axis=1), cmap='gray')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(np.concatenate((imgs_aug), axis=1), cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Familiarize yourself with the different augmentations available through <code>imgaug</code>. <br>\n",
    "Refer to the <a href = \"https://github.com/aleju/imgaug\">examples</a> and the <a href=\"https://imgaug.readthedocs.io/en/latest/\">documentation</a>. Identify and apply augmentations that you think are interesting.\n",
    "</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
